{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e8af493",
   "metadata": {},
   "source": [
    "# STATUS: Complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7989fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "67e3c31b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62721c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_name: str) -> str:\n",
    "    \n",
    "    # \"java_0_code_text_file.txt\"\n",
    "    # \"Java_0_Complete_Program.txt\"\n",
    "    \n",
    "    # open file as text_file\n",
    "    with open(file_name, \"r\") as text_file: \n",
    "        \n",
    "        # save all the data in the file in lines\n",
    "        lines = text_file.read()\n",
    "        \n",
    "        # return lines converted to lowercase\n",
    "        return lines.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "089b32ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_file(\"java_0_input.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bd88f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv(file_name: str) -> list:\n",
    "\n",
    "    # initializing the following lists\n",
    "    fields: list = []\n",
    "    rows_list: list = []\n",
    "    table: list = []\n",
    "\n",
    "    # open the CSV file \n",
    "    with open(file_name, 'r') as csv_file:\n",
    "        \n",
    "        # save the data from csv_file to csv_reader\n",
    "        csv_reader = csv.reader(csv_file)\n",
    "\n",
    "        # save the fields row to fields\n",
    "        fields = next(csv_reader)\n",
    "\n",
    "        # get each row and save it to rows\n",
    "        for row in csv_reader:\n",
    "            rows_list.append(row)\n",
    " \n",
    "    # add the fields to table\n",
    "    table.append(fields)\n",
    "    \n",
    "    # get all the rows from rows_list and add them to table\n",
    "    for row in rows_list:\n",
    "        table.append(row)\n",
    "         \n",
    "    # returns the table\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69342fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_csv(\"Java_0_DFSA_Table.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b90e65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dictionary(file_name: str) -> dict:\n",
    "\n",
    "    # open the CSV file \n",
    "    with open(file_name, 'r') as csv_file:\n",
    "        \n",
    "        # get an ordered dictionary of the data\n",
    "        ordered_dict = csv.DictReader(csv_file)\n",
    "        \n",
    "        # turn it into a common dictionary by putting it in a list\n",
    "        into_dictionary = list(ordered_dict)\n",
    "            \n",
    "        # return the dictionary by itself\n",
    "        return into_dictionary[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88541a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_dictionary(\"Reserved_Words.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "912e52d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_dictionary(\"Reserved_symbols.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a906774",
   "metadata": {},
   "outputs": [],
   "source": [
    "def java_0_DFSM(string: str) -> list:\n",
    "    \n",
    "    # variables to help parse 'string'\n",
    "    current_token: str = \"\"\n",
    "        \n",
    "    token_list: list = []\n",
    "    current_state: str = \"0\"\n",
    "    previous_state: str = \"0\"\n",
    "    comment_flag: bool = False\n",
    "        \n",
    "    table: list = get_csv(\"Java_0_DFSA_Table.csv\")\n",
    "    \n",
    "    any_symbol: list = [\" \", \"\\n\"] + table[0][5:19]\n",
    "        \n",
    "    # this addresses an edge case without the need to add a new condition\n",
    "    string += \" \"\n",
    "\n",
    "    print(\"String being parsed: \\n\\n'\" + string + \"'\")\n",
    "    \n",
    "    # going over each individual character in 'string'\n",
    "    for character in string:\n",
    "\n",
    "        previous_state = current_state\n",
    "\n",
    "        \n",
    "        # COMMENT AND OPERATORS  --------------------------------------------------------\n",
    "\n",
    "\n",
    "        # if comment_flag is True and previous_state is 11\n",
    "        if comment_flag and previous_state == \"11\":\n",
    "            \n",
    "            # keep current_state = 11\n",
    "            current_state = table[12][1]\n",
    "            \n",
    "            # if the character is '*' add it to current_token \n",
    "            # and set current_state to 12 (go to state 12)\n",
    "            if character == \"*\":\n",
    "                current_token += character\n",
    "                current_state = table[12][7]\n",
    "                \n",
    "\n",
    "            # or current_token is '*' and character is '/' \n",
    "            # add '/' to current_token and set current_state to 12 \n",
    "            # now in state 12 we meet the condition that the comment has ended (go to state 12)\n",
    "            elif current_token == \"*\" and character == \"/\":\n",
    "                current_token += character\n",
    "                current_state = table[12][7]\n",
    "                \n",
    "                \n",
    "        # if current_token is '/' and character is anything except '*' (go to state 10)\n",
    "        elif current_token == \"/\" and character != \"*\":\n",
    "            \n",
    "            # if current_token is not whitespace add current_token to token_list\n",
    "            if current_token != \" \":\n",
    "                token_list.append(current_token)\n",
    "        \n",
    "            # reset current_token then add character to token_list\n",
    "            # set current_state = state 10\n",
    "            current_token = \"\"\n",
    "            current_token += character\n",
    "            current_state = table[10][1]\n",
    "            \n",
    "            \n",
    "        # if current_token is '=' and character is not '=' (go to state 14)\n",
    "        elif current_token == \"=\" and character != \"=\":\n",
    "            \n",
    "            # if current_token is not whitespace add current_token to token_list\n",
    "            if current_token != \" \":\n",
    "                token_list.append(current_token)\n",
    "        \n",
    "            # reset current_token then add character to token_list\n",
    "            # set current_state = state 14\n",
    "            current_token = \"\"\n",
    "            current_token += character\n",
    "            current_state = table[14][1]\n",
    "            \n",
    "            \n",
    "        # if current_token is '<' and character is not '=' (go to state 17)\n",
    "        elif current_token == \"<\" and character != \"=\":\n",
    "            \n",
    "            # if current_token is not whitespace add current_token to token_list\n",
    "            if current_token != \" \":\n",
    "                token_list.append(current_token)\n",
    "            \n",
    "            # reset current_token then add character to token_list\n",
    "            # set current_state = state 17\n",
    "            current_token = \"\"\n",
    "            current_token += character\n",
    "            current_state = table[17][1]\n",
    "            \n",
    "            \n",
    "        # if current_token is '>' and character is not '=' (go to state 20)\n",
    "        elif current_token == \">\" and character != \"=\":\n",
    "            \n",
    "            # if current_token is not whitespace add current_token to token_list\n",
    "            if current_token != \" \":\n",
    "                token_list.append(current_token)\n",
    "            \n",
    "            # reset current_token then add character to token_list\n",
    "            # set current_state = state 20\n",
    "            current_token = \"\"\n",
    "            current_token += character\n",
    "            current_state = table[20][1]\n",
    "            \n",
    "            \n",
    "        # if current_token is '!' and character is not '=' (go to state 1)\n",
    "        elif current_token == \"!\" and character != \"=\":\n",
    "            \n",
    "            # reset current_token then add character to token_list\n",
    "            # set current_state = state 1\n",
    "            current_token = \"\"\n",
    "            current_state = table[23][1]\n",
    "\n",
    "\n",
    "        # LETTERS, DIGITS, AND SYMBOLS IF LETTER/DIGIT ADJACENT ----------------------\n",
    "\n",
    "    \n",
    "        # if we have a character from any_symbol following a letter (go to state 3)\n",
    "        elif character in any_symbol and previous_state == \"2\": \n",
    "            \n",
    "            # if a character from any_symbol is encountered we add the current_token\n",
    "            # to token_list and proceed with this state to get the symbol individually\n",
    "            # so long as character is not whitespace\n",
    "            if character != \" \":\n",
    "                token_list.append(current_token)\n",
    "                current_token = \"\"\n",
    "                current_token += character\n",
    "\n",
    "            # we have a <variable identifier> set current_state = state 3\n",
    "            current_state = table[3][1]\n",
    "\n",
    "\n",
    "        # if we have a digit following a letter (go to state 2)\n",
    "        elif character.isdigit() and current_state == \"2\":\n",
    "            \n",
    "            # add the character to current_token\n",
    "            # set current_state = state 2\n",
    "            current_token += character\n",
    "            current_state = table[1][3] \n",
    "\n",
    "            \n",
    "        # if we have a letter (state 2)\n",
    "        elif character.isalpha():\n",
    "            \n",
    "            # add the character to current_token\n",
    "            # set current_state = state 2 \n",
    "            current_token += character\n",
    "            current_state = table[1][3]\n",
    "\n",
    "\n",
    "        # if we have a character from any_symbol following a digit (go to state 4)\n",
    "        elif character in any_symbol and previous_state == \"4\": # state 4: digit\n",
    "            \n",
    "            # if a character from any_symbol is encountered we add the current_token\n",
    "            # to token_list and proceed with this state to get the symbol individually\n",
    "            # so long as character is not whitespace\n",
    "            if character != \" \":\n",
    "                token_list.append(current_token)\n",
    "                current_token = \"\"\n",
    "                current_token += character\n",
    "            \n",
    "            # we have an <integer> set current_state = state 5\n",
    "            current_state = table[5][1]\n",
    "\n",
    "\n",
    "        # if we have a digit (go to state 4)\n",
    "        elif character.isdigit():\n",
    "            \n",
    "            # add the digit to current_token\n",
    "            # set current_state = state 4\n",
    "            current_token += character\n",
    "            current_state = table[1][4]\n",
    "            \n",
    "        \n",
    "        # OPERATORS AND COMMENTS ---------------------------------------------------\n",
    "        \n",
    "        \n",
    "        # if we have '/*' as a token and previous_state is 9 (go to state 11)\n",
    "        elif current_token == \"/\" and character == \"*\" and previous_state == \"9\":\n",
    "            \n",
    "            # add the '*' to current_token\n",
    "            # set current_state = state 11\n",
    "            current_token += character\n",
    "            current_state = table[10][7]\n",
    "            \n",
    "\n",
    "        # if we have '==' as a token and previous_state is 13 (go to state 15)\n",
    "        elif current_token == \"=\" and character == \"=\" and previous_state == \"13\":\n",
    "            \n",
    "            # add the '=' to current_token\n",
    "            # set current_state = state 15\n",
    "            current_token += character \n",
    "            current_state = table[14][9]\n",
    "            \n",
    "            \n",
    "        # if we have '<=' as a token and previous_state is 16 (go to state 18)\n",
    "        elif current_token == \"<\" and character == \"=\" and previous_state == \"16\":\n",
    "            \n",
    "            # add the '=' to current_token\n",
    "            # set current_state = state 18\n",
    "            current_token += character \n",
    "            current_state = table[17][9]\n",
    "            \n",
    "            \n",
    "        # if we have '>=' as a token and previous_state is 19 (go to state 21)\n",
    "        elif current_token == \">\" and character == \"=\" and previous_state == \"19\":\n",
    "            \n",
    "            # add the '=' to current_token\n",
    "            # set current_state = state 21\n",
    "            current_token += character \n",
    "            current_state = table[20][9]\n",
    "            \n",
    "            \n",
    "        # if we have '!=' as a token and previous_state is 22 (go to state 23)\n",
    "        elif current_token == \"!\" and character == \"=\" and previous_state == \"22\":\n",
    "            \n",
    "            # add the '=' to current_token\n",
    "            # set current_state = state 23\n",
    "            current_token += character \n",
    "            current_state = table[23][9]\n",
    "            \n",
    "            \n",
    "        # if we have a '+' sign (go to state 6)\n",
    "        elif character == \"+\": \n",
    "            \n",
    "            # add '+' to current_token\n",
    "            # set current_state = state 6\n",
    "            current_token += character\n",
    "            current_state = table[1][5]\n",
    "            \n",
    "            \n",
    "        # if we have a '-' sign (go to state 7)\n",
    "        elif character == \"-\": \n",
    "            \n",
    "            # add '-' to current_token\n",
    "            # set current_state = state 7\n",
    "            current_token += character\n",
    "            current_state = table[1][6]\n",
    "\n",
    "        \n",
    "        # if we have a '*' sign (go to state 8)\n",
    "        elif character == \"*\": \n",
    "            \n",
    "            # add '*' to current_token\n",
    "            # set current_state = state 8\n",
    "            current_token += character\n",
    "            current_state = table[1][7]\n",
    "            \n",
    "        \n",
    "        # if we have a '/' sign (go to state 9)\n",
    "        elif character == \"/\": \n",
    "            \n",
    "            # add '/' to current_token \n",
    "            # set current_state = state 9\n",
    "            current_token += character\n",
    "            current_state = table[1][8]\n",
    "              \n",
    "        \n",
    "        # if we have a '=' sign (go to state 13)\n",
    "        elif character == \"=\":\n",
    "            \n",
    "            # add '=' to current_token\n",
    "            # set current_state = state 13\n",
    "            current_token += character\n",
    "            current_state = table[1][9]\n",
    "            \n",
    "        \n",
    "        # if we have a '<' sign (go to state 16)\n",
    "        elif character == \"<\":\n",
    "            \n",
    "            # add '<' to current_token\n",
    "            # set current_state = state 16\n",
    "            current_token += character\n",
    "            current_state = table[1][10]\n",
    "            \n",
    "        \n",
    "        # if we have a '>' sign (go to state 19)\n",
    "        elif character == \">\":\n",
    "            \n",
    "            # add '>' to current_token\n",
    "            # set current_state = state 19\n",
    "            current_token += character\n",
    "            current_state = table[1][11]\n",
    "            \n",
    "            \n",
    "        # if we have a '!' sign (go to state 22)\n",
    "        elif character == \"!\":\n",
    "            \n",
    "            # add '!' to current_token\n",
    "            # set current_state = state 22\n",
    "            current_token += character\n",
    "            current_state = table[1][12]\n",
    "            \n",
    "            \n",
    "        # PARENTHESIS AND BRACES ---------------------------------------------------\n",
    "        \n",
    "        \n",
    "        # if we have a '(' sign (go to state 24)\n",
    "        elif character == \"(\": \n",
    "            \n",
    "            # add '(' to current_token\n",
    "            # set current_state = state 24\n",
    "            current_token += character\n",
    "            current_state = table[1][13]\n",
    "            \n",
    "        \n",
    "        # if we have a ')' sign (go to state 25)\n",
    "        elif character == \")\": \n",
    "            \n",
    "            # add ')' to current_token\n",
    "            # set current_state = state 25\n",
    "            current_token += character\n",
    "            current_state = table[1][14]\n",
    "           \n",
    "        \n",
    "        # if we have a '{' sign (go to state 26)\n",
    "        elif character == \"{\": \n",
    "            \n",
    "            # add '{' to current_token\n",
    "            # set current_state = state 26\n",
    "            current_token += character\n",
    "            current_state = table[1][15]\n",
    "            \n",
    "            \n",
    "        # if we have a '}' sign (go to state 27)\n",
    "        elif character == \"}\": \n",
    "            \n",
    "            # add '}' to current_token\n",
    "            # set current_state = state 27\n",
    "            current_token += character\n",
    "            current_state = table[1][16]\n",
    "            \n",
    "        \n",
    "        # COMMA AND SEMICOLON ------------------------------------------------------\n",
    "        \n",
    "        \n",
    "        # if we have a ',' sign (go to state 28)\n",
    "        elif character == \",\": \n",
    "            \n",
    "            # add ',' to current_token\n",
    "            # set current_state = state 28\n",
    "            current_token += character\n",
    "            current_state = table[1][15]\n",
    "            \n",
    "            \n",
    "        # if we have a ';' sign (go to state 29)\n",
    "        elif character == \";\": \n",
    "            \n",
    "            # add ';' to current_token\n",
    "            # set current_state = state 29\n",
    "            current_token += character\n",
    "            current_state = table[1][16]\n",
    "        \n",
    "            \n",
    "        # SPACE AND UNIDENTIFIED SYMBOLS -------------------------------------------\n",
    "            \n",
    "            \n",
    "        # if we have whitespace (go to state 0)\n",
    "        elif character == \" \" or character == \"\\n\":\n",
    "            \n",
    "            # set current_state = state 0\n",
    "            current_state = table[1][1]\n",
    "            \n",
    "            \n",
    "        # otherwise we have an unidentified symbol (go to state 1)\n",
    "        else:\n",
    "            \n",
    "            # set current_state = state 1\n",
    "            print(character)\n",
    "            current_state = table[1][2]\n",
    "            \n",
    "            \n",
    "        # CASE STATEMENTS FOR current_state ---------------------------------------\n",
    "    \n",
    "    \n",
    "        # we check current_state and proceed accordingly\n",
    "        match current_state:\n",
    "\n",
    "            \n",
    "            # case 0\n",
    "            case \"0\":\n",
    "                current_token = \"\"\n",
    "\n",
    "                \n",
    "            # case 1\n",
    "            case \"1\":\n",
    "                print(\"Illegal character\")\n",
    "                break\n",
    "\n",
    "                \n",
    "            # case 2 \n",
    "            case \"2\":\n",
    "                pass\n",
    "\n",
    "                \n",
    "            # case 3 ( [a-zA-Z] )\n",
    "            case \"3\":\n",
    "                if current_token != \"\\n\":\n",
    "                    token_list.append(current_token)\n",
    "                \n",
    "                current_token = \"\"\n",
    "                current_state = \"0\"\n",
    "\n",
    "                \n",
    "            # case 4\n",
    "            case \"4\":\n",
    "                pass\n",
    "\n",
    "                \n",
    "            # case 5 ( [0-9] )\n",
    "            case \"5\":\n",
    "                if current_token != \"\\n\":\n",
    "                    token_list.append(current_token)\n",
    "                    \n",
    "                current_token = \"\"\n",
    "                current_state = \"0\"\n",
    "\n",
    "                \n",
    "            # case 6 ( + )\n",
    "            case \"6\":\n",
    "                token_list.append(current_token)\n",
    "                current_token = \"\"\n",
    "                current_state = \"0\"\n",
    "                \n",
    "            \n",
    "            # case 7 ( - )\n",
    "            case \"7\":\n",
    "                token_list.append(current_token)\n",
    "                current_token = \"\"\n",
    "                current_state = \"0\"\n",
    "                \n",
    "            \n",
    "            # case 8 ( * )\n",
    "            case \"8\":\n",
    "                token_list.append(current_token)\n",
    "                current_token = \"\"\n",
    "                current_state = \"0\"\n",
    "                \n",
    "            \n",
    "            # case 9 \n",
    "            case \"9\":\n",
    "                pass\n",
    "                \n",
    "            \n",
    "            # case 10 ( / )\n",
    "            case \"10\":\n",
    "                if current_token != \" \":\n",
    "                    token_list.append(current_token)\n",
    "                    \n",
    "                current_token = \"\"\n",
    "                current_state = \"0\"\n",
    "                \n",
    "\n",
    "            # case 11 ( /* )\n",
    "            case \"11\":\n",
    "                comment_flag = True\n",
    "                current_token = \"\"\n",
    "                current_state = \"11\"\n",
    "                \n",
    "                \n",
    "            # case 12 ( */ )\n",
    "            case \"12\":\n",
    "                if current_token == \"*/\":\n",
    "                    current_token = \"\"\n",
    "                    current_state = \"0\"\n",
    "                    comment_flag = False\n",
    "                    \n",
    "                else:\n",
    "                    current_state = \"11\"\n",
    "                    \n",
    "                    \n",
    "            # case 13\n",
    "            case \"13\":\n",
    "                pass\n",
    "\n",
    "            \n",
    "            # case 14 ( = )\n",
    "            case \"14\":\n",
    "                if current_token != \" \":\n",
    "                    token_list.append(current_token)\n",
    "                    \n",
    "                current_token = \"\"\n",
    "                current_state = \"0\"\n",
    "                    \n",
    "            \n",
    "            # case 15 ( == )\n",
    "            case \"15\":\n",
    "                token_list.append(current_token)\n",
    "                current_token = \"\"\n",
    "                current_state = \"0\"\n",
    "                \n",
    "                               \n",
    "            # case 16\n",
    "            case \"16\":\n",
    "                pass\n",
    "\n",
    "            \n",
    "            # case 17 ( < )\n",
    "            case \"17\":\n",
    "                if current_token != \" \":\n",
    "                    token_list.append(current_token)\n",
    "                    \n",
    "                current_token = \"\"\n",
    "                current_state = \"0\"\n",
    "                    \n",
    "            \n",
    "            # case 18 ( <= )\n",
    "            case \"18\":\n",
    "                token_list.append(current_token)\n",
    "                current_token = \"\"\n",
    "                current_state = \"0\"\n",
    "                \n",
    "                \n",
    "            # case 19\n",
    "            case \"19\":\n",
    "                pass\n",
    "\n",
    "\n",
    "            # case 20 ( > )\n",
    "            case \"20\":\n",
    "                if current_token != \" \":\n",
    "                    token_list.append(current_token)\n",
    "                    \n",
    "                current_token = \"\"\n",
    "                current_state = \"0\"\n",
    "                    \n",
    "            \n",
    "            # case 21 ( >= )\n",
    "            case \"21\":\n",
    "                token_list.append(current_token)\n",
    "                current_token = \"\"\n",
    "                current_state = \"0\"\n",
    "                \n",
    "            \n",
    "            # case 22\n",
    "            case \"22\":\n",
    "                pass\n",
    "\n",
    "                \n",
    "            # case 23 ( != )\n",
    "            case \"23\":\n",
    "                token_list.append(current_token)\n",
    "                current_token = \"\"\n",
    "                current_state = \"0\"\n",
    "                \n",
    "            \n",
    "            # case 24 ( ( )\n",
    "            case \"24\":\n",
    "                token_list.append(current_token)\n",
    "                current_token = \"\"\n",
    "                current_state = \"0\"\n",
    "                \n",
    "            \n",
    "            # case 25 ( ) )\n",
    "            case \"25\":\n",
    "                token_list.append(current_token)\n",
    "                current_token = \"\"\n",
    "                current_state = \"0\"\n",
    "                \n",
    "                \n",
    "            # case 26 ( { )\n",
    "            case \"26\":\n",
    "                token_list.append(current_token)\n",
    "                current_token = \"\"\n",
    "                current_state = \"0\"\n",
    "                \n",
    "            \n",
    "            # case 27 ( } )\n",
    "            case \"27\":\n",
    "                token_list.append(current_token)\n",
    "                current_token = \"\"\n",
    "                current_state = \"0\"\n",
    "                \n",
    "                \n",
    "            # case 28 ( , )\n",
    "            case \"28\":\n",
    "                token_list.append(current_token)\n",
    "                current_token = \"\"\n",
    "                current_state = \"0\"\n",
    "                \n",
    "            \n",
    "            # case 29 ( ; )\n",
    "            case \"29\":\n",
    "                token_list.append(current_token)\n",
    "                current_token = \"\"\n",
    "                current_state = \"0\"\n",
    "                \n",
    "                \n",
    "            # unidentified case\n",
    "            case unknown_command:\n",
    "                print(\"Invalid input.\")\n",
    "            \n",
    "    \n",
    "        # END OF CASE STATEMENTS FOR current_state -------------------------------\n",
    "    \n",
    "    # return the token list\n",
    "    return token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3534331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# java_0_DFSM(read_file(\"Java_0_input.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7265619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# java_0_DFSM(read_file(\"test_text.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee080316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_classification_table(token_list: list) -> list:\n",
    "    \n",
    "    # variables to help get the token_classification_list\n",
    "    token_clasification_list: list = []\n",
    "    program_name_flag: bool = False\n",
    "    constant_type_flag: bool = False\n",
    "    \n",
    "    # get the dictionaries of reserved words and symbols\n",
    "    reserved: list = get_dictionary(\"Reserved_Words.csv\")\n",
    "    symbols: list = get_dictionary(\"Reserved_Symbols.csv\")\n",
    "    \n",
    "    \n",
    "    # we go through each token \n",
    "    for token in token_list:\n",
    "        \n",
    "        \n",
    "        # first we check if the token is a reserved word\n",
    "        if token in reserved:\n",
    "            \n",
    "            # if so we add it to the token_classification_list along with the classification\n",
    "            token_clasification_list.append((token, reserved[token]))\n",
    "            \n",
    "            # the token is 'class' we turn on program_name_flag\n",
    "            if token == \"class\":\n",
    "                program_name_flag = True\n",
    "                \n",
    "            # the token is 'const' we turn on constant_type_flag\n",
    "            if token == \"const\":\n",
    "                constant_type_flag = True\n",
    "            \n",
    "        \n",
    "        # if program_name_flag is on we add the token and the clasification to token_classification_list\n",
    "        # and turn off program_name_flag\n",
    "        elif program_name_flag:\n",
    "            token_clasification_list.append((token, \"<program name>\"))\n",
    "            program_name_flag = False\n",
    "    \n",
    "        \n",
    "        # we check that constant_type_flag is on and that the token is not a digit or symbol\n",
    "        # and we add the token and the clasification to token_classification_list\n",
    "        elif (constant_type_flag and token not in symbols and not token.isdigit()):\n",
    "            token_clasification_list.append((token, \"<constant identifier>\"))\n",
    "            \n",
    "        \n",
    "        # if the token is a digit add the token and the clasification to token_classification_list\n",
    "        elif token.isdigit():\n",
    "            token_clasification_list.append((token, \"<numeric literal>\"))\n",
    "            \n",
    "            \n",
    "        # if the token has letters and digits add the token and the clasification to token_classification_list\n",
    "        elif token.isalnum():\n",
    "            token_clasification_list.append((token, \"<variable identifier>\"))\n",
    "            \n",
    "            \n",
    "        # if the token is a reserved symbol\n",
    "        elif token in symbols:\n",
    "            \n",
    "            # if the token is a semicolon we turn off the constant_type_flag\n",
    "            if token == \";\":\n",
    "                constant_type_flag = False\n",
    "            \n",
    "            # we add the token and the clasification to token_classification_list\n",
    "            token_clasification_list.append((token, symbols[token]))\n",
    "            \n",
    "        # otherwise print that the token has no classification \n",
    "        else:\n",
    "            print(\"No classification for:\", token)\n",
    "\n",
    "    \n",
    "    # return the token classification list\n",
    "    return token_clasification_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5224f4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# token_classification_table(java_0_DFSM(read_file(\"java_0_code_text_file.txt\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd9adc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_csv(token_clasification_list: list) -> list:\n",
    "    \n",
    "    # create the CSV file\n",
    "    with open('Token_Classification_Table.csv', 'w', newline='') as csv_file:\n",
    "            \n",
    "        # get the header\n",
    "        header = [\"Token\", \"Classification\"]\n",
    "        \n",
    "        # set up our writer object\n",
    "        writer = csv.writer(csv_file)\n",
    "        \n",
    "        # write the header to the CSV file\n",
    "        writer.writerow(header)\n",
    "        \n",
    "        # we write each token along with its classification in the CSV file\n",
    "        for token in token_clasification_list:\n",
    "            writer.writerow([token[0], token[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0350d4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_symbol_table(token_classification_list: list) -> list:\n",
    "    \n",
    "    # some variables to help us\n",
    "    row_number: int = 1\n",
    "    temp_counter: int = 1\n",
    "    address_counter: int = 0\n",
    "    token_classifications: list = []\n",
    "    symbol_table: list = []\n",
    "    variable_list: list = []\n",
    "    header: list = []\n",
    "    \n",
    "    # we get the classifications\n",
    "    token_classifications = token_classification_list\n",
    "        \n",
    "    # we create the symbol table\n",
    "    with open(\"Symbol_Table.csv\", 'w', newline='') as csv_file:\n",
    "            \n",
    "        # we get the header\n",
    "        header = [\" \", \"Symbol\", \"Classification\", \"Value\", \"Address\", \"Segment\"]\n",
    "        \n",
    "        # we get our writer object\n",
    "        writer = csv.writer(csv_file)\n",
    "        \n",
    "        \n",
    "        # we get the data needed into the table ----------------------------------------------\n",
    "        \n",
    "        \n",
    "        # we go through every token in the classification table\n",
    "        for index, token in enumerate(token_classifications):\n",
    "            \n",
    "            \n",
    "            # if the token is classified as the program name\n",
    "            if token[1] == \"<program name>\":\n",
    "                \n",
    "                # we add the data to symbol_table\n",
    "                symbol_table.append(list([row_number, token[0], token[1], \"\", \"0\", \"CS\"]))\n",
    "                \n",
    "            \n",
    "            # if the token is a variable or constant identifier and the next token is a '='\n",
    "            # and the token next to it is a digit\n",
    "            if ((token[1] == \"<variable identifier>\" or token[1] == \"<constant identifier>\") and \n",
    "                  token_classifications[index + 1][0] == \"=\" and \n",
    "                  token_classifications[index + 2][0].isdigit()):\n",
    "\n",
    "                # add the variable to the list\n",
    "                variable_list.append(token[0])\n",
    "                \n",
    "                # we add the data to symbol_table\n",
    "                symbol_table.append(\n",
    "                    list([row_number, token[0], token[1], token_classifications[index + 2][0], \"0\", \"DS\"])\n",
    "                )\n",
    "                \n",
    "                \n",
    "            # if the token is a variable identifier and the token is not in variable_list\n",
    "            elif token[1] == \"<variable identifier>\" and token[0] not in variable_list:\n",
    "                variable_list.append(token[0])\n",
    "                \n",
    "                # we add the data to symbol_table\n",
    "                symbol_table.append(list([row_number, token[0], token[1], \"\", \"0\", \"DS\"]))\n",
    "\n",
    "            \n",
    "            # if the token is a numeric literal and the token before it is not a '='\n",
    "            if token[1] == \"<numeric literal>\" and token_classifications[index - 1][0] != \"=\":\n",
    "                \n",
    "                # we add the data to symbol_table\n",
    "                symbol_table.append(list([row_number, token[0], token[1], token[0], \"0\", \"DS\"]))\n",
    "                \n",
    "                \n",
    "            # if the token is an addition, subtraction, mupltiplication, or division operator\n",
    "            if (token[1] == \"<addition operator>\" or \n",
    "                token[1] == \"<multiplication operator>\" or\n",
    "                token[1] == \"<subtraction operator>\" or \n",
    "                token[1] == \"<division operator>\" or \n",
    "                token[1] == \"<equality operator>\" or\n",
    "                token[1] == \"<less than operator>\" or \n",
    "                token[1] == \"<greater than operator>\" or\n",
    "                token[1] == \"<less than equals operator>\" or\n",
    "                token[1] == \"<greater than equals operator>\" or \n",
    "                token[1] == \"<not equals operator>\"):\n",
    "                \n",
    "                # we add the data to symbol_table\n",
    "                symbol_table.append(list([row_number, \"temp\", \"\", \"\", \"\" \"\"]))\n",
    "\n",
    "                \n",
    "        # now we format the symbol table -------------------------------------------------\n",
    "        \n",
    "        \n",
    "        # we check every row for the ones holding 'temp' in the symbol column\n",
    "        for row in symbol_table:\n",
    "            if \"temp\" in row[1]:\n",
    "                \n",
    "                # we move the row to the bottom of the list\n",
    "                symbol_table.append(symbol_table.pop(symbol_table.index(row)))\n",
    "                \n",
    "        \n",
    "        # if a row has 'temp' in the symbol column we modify them by adding numbers \n",
    "        # to them in ascending order\n",
    "        for row in symbol_table:\n",
    "            if \"temp\" in row[1]:\n",
    "                row[1] += str(temp_counter)\n",
    "                temp_counter += 1\n",
    "                \n",
    "                \n",
    "        # we add the proper row number to each row\n",
    "        for row in symbol_table:\n",
    "            row[0] = row_number\n",
    "            row_number += 1\n",
    "            \n",
    "            \n",
    "        # we fix the address counter to each row\n",
    "        for row in symbol_table[1:]:\n",
    "            if row[4] == \"0\":\n",
    "                row[4] = address_counter\n",
    "                address_counter += 2\n",
    "                \n",
    "                \n",
    "        # we insert the header at the top \n",
    "        symbol_table.insert(0, header)\n",
    "        \n",
    "        \n",
    "        # finally we write the table to the CSV file\n",
    "        for row in symbol_table:\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa9587e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# token_symbol_table(token_classification_table(java_0_DFSM(read_file(\"java_0_code_text_file.txt\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ca35807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_analyzer(file_name: str) -> str:\n",
    "    \n",
    "    # we declare the variable for the token list and its classifications, and the symbol table\n",
    "    token_list: list = []\n",
    "    token_classifications: list = []\n",
    "    symbol_table: list = []\n",
    "\n",
    "    # we save the token list and its classifications to the respective variable \n",
    "    token_list = java_0_DFSM(read_file(file_name))\n",
    "    token_classifications = token_classification_table(token_list)\n",
    "    \n",
    "    # we write the token classification and symbol table into a CSV file\n",
    "    write_to_csv(token_classifications)\n",
    "    symbol_table = token_symbol_table(token_classifications)\n",
    "    \n",
    "    return \"Lexical analysis complete.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8931e9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String being parsed: \n",
      "\n",
      "'class pgm1{\n",
      "    const m = 7, n = 85;\n",
      "    var x, y, z;\n",
      "\n",
      "    x = m + y * z + 12\n",
      "} '\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    lexical_analyzer(\"java_0_code_text_file.txt\") # java_0_code_text_file.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cd0793",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5182cc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b4959d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb01a02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c538e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952629fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
